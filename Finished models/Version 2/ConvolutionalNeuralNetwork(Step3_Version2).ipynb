{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionalNeuralNetwork(Step3-Version2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVKggTl6WLZm"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "p_camelyon, p_camelyon_info = tfds.load(\"patch_camelyon\", with_info=True)"
      ],
      "metadata": {
        "id": "GXvcIUlyWWgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a \"normalize\" function to process the data before feeding it into the deep neural network. \n",
        "\n",
        "def normalize(x):\n",
        "  image, label = x['image'], x['label']\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  label = tf.one_hot(label, 2, dtype=tf.float32)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "6ZHl7uBsWXtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying \"normalize\" function along with others to the data\n",
        "\n",
        "# Processing the training dataset\n",
        "train_ds = p_camelyon['train'].map(normalize, num_parallel_calls=8)\n",
        "train_ds = train_ds.shuffle(1024)\n",
        "train_ds = train_ds.repeat()\n",
        "train_ds = train_ds.batch(32)\n",
        "train_ds = train_ds.prefetch(2)\n",
        "\n",
        "# Processing validation dataset\n",
        "validation_ds = p_camelyon['validation'].map(normalize, num_parallel_calls=8)\n",
        "validation_ds = validation_ds.repeat()\n",
        "validation_ds = validation_ds.batch(128)\n",
        "validation_ds = validation_ds.prefetch(2)\n",
        "\n",
        "#Processing the test dataset\n",
        "test_ds = p_camelyon['test'].map(normalize, num_parallel_calls=8)\n",
        "test_ds = test_ds.batch(128)\n",
        "test_ds = test_ds.prefetch(2)\n",
        "\n",
        "#Seperating image and label into different variables\n",
        "train_images, train_labels = next(iter(train_ds))\n",
        "valid_images, valid_labels = next(iter(validation_ds))\n",
        "test_images, test_labels  = next(iter(test_ds))\n"
      ],
      "metadata": {
        "id": "vSplKW0FWYrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Nueral Network Model 1.1 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# Relu activation functions only, with softmax activation function for the last Dense layer\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "# Loss function = hinge\n",
        "model_1_1_version_2 = Model(inputs=input, outputs = output)\n",
        "model_1_1_version_2.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.Hinge(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_1_1_version_2.summary()\n",
        "plot_model(model_1_1_version_2)"
      ],
      "metadata": {
        "id": "C-VfrGV2WacS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Nueral Network Model 1.2 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# Relu activation functions only, with softmax activation function for the last Dense layer\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "# Loss function =   MSE\n",
        "model_1_2_version_2 = Model(inputs=input, outputs = output)\n",
        "model_1_2_version_2.compile(optimizer='adam', \n",
        "              loss='MSE',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_1_2_version_2.summary()\n",
        "#plot_model(model_1_2_version_2)"
      ],
      "metadata": {
        "id": "BhN4R6heWt3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Nueral Network Model 2.1 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# Sigmoid activation functions only with softmax for the last Dense layer\n",
        "\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "# Loss function = hinge\n",
        "model_2_2_version_2 = Model(inputs=input, outputs = output)\n",
        "model_2_2_version_2.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.Hinge(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_2_2_version_2.summary()\n",
        "#plot_model(model_2_2_version_2)"
      ],
      "metadata": {
        "id": "SsO2ci0XW4An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Nueral Network Model 2.2 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# Sigmoid activation functions only with softmax for the last Dense layer\n",
        "\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "# Loss function = MSE\n",
        "model_2_2_version_2 = Model(inputs=input, outputs = output)\n",
        "model_2_2_version_2.compile(optimizer='adam', \n",
        "              loss='MSE',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_2_2_version_2.summary()\n",
        "#plot_model(model_2_2_version_2)"
      ],
      "metadata": {
        "id": "v3anEzRaXMpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Neural Network Model 3.1 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# A conbination of relu and sigmoid activation functions\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "# Loss function = hinge\n",
        "model_3_1_version_2 = Model(inputs=input, outputs = output)\n",
        "model_3_1_version_2.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.Hinge(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_3_1_version_2.summary()\n",
        "#plot_model(model_3_1_version_2)"
      ],
      "metadata": {
        "id": "3qaGtD5RXTeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Neural Network Model 3.2 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# A conbination of relu and sigmoid activation functions\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(64, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "# Loss function = MSE\n",
        "model_3_2 = Model(inputs=input, outputs = output)\n",
        "model_3_2.compile(optimizer='adam', \n",
        "              loss='MSE',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_3_2.summary()\n",
        "#plot_model(model_3_2)"
      ],
      "metadata": {
        "id": "s5pAexHlXlfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size_for_training = 32\n",
        "batch_size_for_validation = 128\n",
        "batch_size_for_test = 128\n",
        "\n",
        "training_size = 262144\n",
        "validation_size = 32768\n",
        "test_size =  32768\n",
        "        \n",
        "\n",
        "# Calculate steps for training and testing the model\n",
        "calculate_steps_training = lambda x: int(math.ceil(1. * x / batch_size_for_training))\n",
        "calculate_steps_validation = lambda x: int(math.ceil(1. * x / batch_size_for_validation))\n",
        "calculate_steps_test= lambda x: int(math.ceil(1. * x / batch_size_for_test))\n",
        "\n",
        "steps_per_epoch = calculate_steps_training(training_size) \n",
        "validation_steps = calculate_steps_validation(validation_size)\n",
        "steps = calculate_steps_test(test_size)\n",
        "\n",
        "print(\"Training steps: \", steps_per_epoch)\n",
        "print(\"Validation steps: \", validation_steps)\n",
        "print(\"Testing steps: \", steps)\n"
      ],
      "metadata": {
        "id": "MWoJTFyDX22e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_hist(history):\n",
        "  plt.plot(history.history[\"acc\"])\n",
        "  plt.plot(history.history[\"val_acc\"])\n",
        "  plt.title(\"Model Accuracy\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6DxAdpBPX3yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model 1.1 (Version 2)\n",
        "\n",
        "history_1_1_version_2= model_1_1_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "on4JIhxfX6mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_1_1_version_2)"
      ],
      "metadata": {
        "id": "5EBn5_CuYOyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model 1.2 (Version 2)\n",
        "\n",
        "history_1_2_version_2= model_1_2_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "3dNhNnHdYGKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_1_2_version_2)"
      ],
      "metadata": {
        "id": "G6AQEICvYTAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model 2.1 (Version 2)\n",
        "\n",
        "history_2_1_version_2= model_2_1_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "FG1MfWg6YJn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_2_1_version_2)"
      ],
      "metadata": {
        "id": "op1uCy4ZYVUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model 2.2 (Version 2)\n",
        "\n",
        "history_2_2_version_2= model_2_2_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "-kfZD9itYYN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_2_2_version_2)"
      ],
      "metadata": {
        "id": "qLyl1czSYdL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model 3.1 (Version 2)\n",
        "\n",
        "history_3_1_version_2= model_3_1_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "Mvo5gEu2Y0ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_3_1_version_2)"
      ],
      "metadata": {
        "id": "5gyLjRPzY_bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model 3.2 (Version 2)\n",
        "\n",
        "history_3_2_version_2= model_3_2_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "lyf-ECcUZDfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_3_2_version_2)"
      ],
      "metadata": {
        "id": "UdkvltbyZDew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the models\n",
        "\n",
        "print(\"Test dataset accuracy for model 1.1 version 2 is: {0:.4f}\".format(model_1_1_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))\n",
        "print(\"Test dataset accuracy for model 1.2 version 2 is: {0:.4f}\".format(model_1_2_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))\n",
        "print(\"Test dataset accuracy for model 2.1 version 2 is: {0:.4f}\".format(model_2_1_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))\n",
        "print(\"Test dataset accuracy for model 2.2 version 2 is: {0:.4f}\".format(model_2_2_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))\n",
        "print(\"Test dataset accuracy for model 3.1 version 2 is: {0:.4f}\".format(model_3_1_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))\n",
        "print(\"Test dataset accuracy for model 3.2 version 2 is: {0:.4f}\".format(model_3_2_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))"
      ],
      "metadata": {
        "id": "RJtmOLpFZ3Pf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}