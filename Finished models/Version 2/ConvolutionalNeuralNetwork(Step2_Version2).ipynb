{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionalNeuralNetwork(Step2-Version2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITKv7i0LUTiY"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "p_camelyon, p_camelyon_info = tfds.load(\"patch_camelyon\", with_info=True)"
      ],
      "metadata": {
        "id": "dRfNgbz5UVtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a \"normalize\" function to process the data before feeding it into the deep neural network. \n",
        "\n",
        "def normalize(x):\n",
        "  image, label = x['image'], x['label']\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  label = tf.one_hot(label, 2, dtype=tf.float32)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "YzI39D_cUl5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying \"normalize\" function along with others to the data\n",
        "\n",
        "# Processing the training dataset\n",
        "train_ds = p_camelyon['train'].map(normalize, num_parallel_calls=8)\n",
        "train_ds = train_ds.shuffle(1024)\n",
        "train_ds = train_ds.repeat()\n",
        "train_ds = train_ds.batch(32)\n",
        "train_ds = train_ds.prefetch(2)\n",
        "\n",
        "# Processing validation dataset\n",
        "validation_ds = p_camelyon['validation'].map(normalize, num_parallel_calls=8)\n",
        "validation_ds = validation_ds.repeat()\n",
        "validation_ds = validation_ds.batch(128)\n",
        "validation_ds = validation_ds.prefetch(2)\n",
        "\n",
        "#Processing the test dataset\n",
        "test_ds = p_camelyon['test'].map(normalize, num_parallel_calls=8)\n",
        "test_ds = test_ds.batch(128)\n",
        "test_ds = test_ds.prefetch(2)\n",
        "\n",
        "#Seperating image and label into different variables\n",
        "train_images, train_labels = next(iter(train_ds))\n",
        "valid_images, valid_labels = next(iter(validation_ds))\n",
        "test_images, test_labels  = next(iter(test_ds))\n"
      ],
      "metadata": {
        "id": "Ca1LUefYUoPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size_for_training = 32\n",
        "batch_size_for_validation = 128\n",
        "batch_size_for_test = 128\n",
        "\n",
        "training_size = 262144\n",
        "validation_size = 32768\n",
        "test_size =  32768\n",
        "        \n",
        "\n",
        "# Calculate steps for training and testing the model\n",
        "calculate_steps_training = lambda x: int(math.ceil(1. * x / batch_size_for_training))\n",
        "calculate_steps_validation = lambda x: int(math.ceil(1. * x / batch_size_for_validation))\n",
        "calculate_steps_test= lambda x: int(math.ceil(1. * x / batch_size_for_test))\n",
        "\n",
        "steps_per_epoch = calculate_steps_training(training_size) \n",
        "validation_steps = calculate_steps_validation(validation_size)\n",
        "steps = calculate_steps_test(test_size)\n",
        "\n",
        "print(\"Training steps: \", steps_per_epoch)\n",
        "print(\"Validation steps: \", validation_steps)\n",
        "print(\"Testing steps: \", steps)\n"
      ],
      "metadata": {
        "id": "PExeDEFKVwpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Different activation functions"
      ],
      "metadata": {
        "id": "k-Liy3g-UsuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MaxPool2D\n",
        "\n",
        "# Building the Convolutonal Neural Network Model 1 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# Relu activation functions only, with softmax activation function for the last Dense layer\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='relu', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "#Optimiser = adam\n",
        "model_1_version_2 = Model(inputs=input, outputs = output)\n",
        "model_1_version_2.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_1_version_2.summary()"
      ],
      "metadata": {
        "id": "yFydnNi2Uq2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model_1_version_2)"
      ],
      "metadata": {
        "id": "edXVbCHDVB4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Neural Network Model 2 (Version2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# Sigmoid activation functions only with softmax for the last Dense layer\n",
        "\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "model_1_version_2 = Model(inputs=input, outputs = output)\n",
        "model_1_version_2.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_1_version_2.summary()"
      ],
      "metadata": {
        "id": "UouUdm65VEQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutonal Neural Network Model 3 (Version 2)\n",
        "\n",
        "# Setting up the output with the right size\n",
        "input = Input(shape=(96,96,3))\n",
        "\n",
        "# A conbination of relu and sigmoid activation functions\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='valid')(x)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "x = Conv2D(64, (3,3), activation='sigmoid', padding='valid')(x)\n",
        "x = Conv2D(16, (3,3), activation='sigmoid', padding='valid')(input)\n",
        "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(rate=0.3)(x)\n",
        "x = Dense(128, activation='sigmoid')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Optimizer = adam\n",
        "model_3_version_2 = Model(inputs=input, outputs = output)\n",
        "model_3_version_2.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model_3_version_2.summary()\n",
        "plot_model(model_3_version_2)"
      ],
      "metadata": {
        "id": "zmmCE0GfVNd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "history_1_version_2= model_1_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "dwUz6fZLV0Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history1_version_2)"
      ],
      "metadata": {
        "id": "7kzxRfVbamcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "history_2_version_2= model_2_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "hFsmQeWUV9M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_2_version_2)"
      ],
      "metadata": {
        "id": "J9PhHmK_ao4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "history_3_version_2= model_3_version_2.fit(train_ds, validation_data=validation_ds, epochs = 10, verbose = 1, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "0pdGr2efWANh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_hist(history_3_version_2)"
      ],
      "metadata": {
        "id": "YL4vDQfgarit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the models\n",
        "\n",
        "print(\"Test dataset accuracy for model 1 version 2 is: {0:.4f}\".format(model_1_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))\n",
        "print(\"Test dataset accuracy for model 2 version 2 is: {0:.4f}\".format(model_2_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))\n",
        "print(\"Test dataset accuracy for model 3 version 2 is: {0:.4f}\".format(model_3_version_2.evaluate(test_ds, steps=steps, verbose=1)[1]))"
      ],
      "metadata": {
        "id": "QeJjjDdJavAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}